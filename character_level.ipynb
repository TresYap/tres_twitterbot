{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character-level modelling implementation where model tries to predict the next character in a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>imagine recycling old game mechanics and calli...</td>\n",
       "      <td>2020-06-21 05:19:43+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imagine making ellie sing a full acoustic cove...</td>\n",
       "      <td>2020-06-21 04:49:42+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>imagine a studio expecting their game to be a ...</td>\n",
       "      <td>2020-06-21 04:43:58+00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Our love for anime girls actually stems from t...</td>\n",
       "      <td>2020-06-19 03:12:37+00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>i find it hard to believe that women should we...</td>\n",
       "      <td>2020-06-15 05:12:23+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  imagine recycling old game mechanics and calli...   \n",
       "1           1  imagine making ellie sing a full acoustic cove...   \n",
       "2           2  imagine a studio expecting their game to be a ...   \n",
       "3           4  Our love for anime girls actually stems from t...   \n",
       "4           5  i find it hard to believe that women should we...   \n",
       "\n",
       "                        date  favorites  retweets hashtags  \n",
       "0  2020-06-21 05:19:43+00:00          4         0      NaN  \n",
       "1  2020-06-21 04:49:42+00:00          3         0      NaN  \n",
       "2  2020-06-21 04:43:58+00:00         10         0      NaN  \n",
       "3  2020-06-19 03:12:37+00:00          9         3      NaN  \n",
       "4  2020-06-15 05:12:23+00:00         17         4      NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    646.000000\n",
       "mean      85.597523\n",
       "std       49.488161\n",
       "min        9.000000\n",
       "25%       48.250000\n",
       "50%       79.000000\n",
       "75%      112.000000\n",
       "max      279.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.text.str.cat(sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagine recycling old game mechanics and calling the last of us 2 an innovative game\n",
      "imagine making ellie sing a full acoustic cover of take on me and expecting the last of us 2 to be a game of the year contender\n",
      "imagine a studio expecting their game to be a masterpiece after ove\n"
     ]
    }
   ],
   "source": [
    "print(text[:280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing characters\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'imagine recyc' ---- characters mapped to int ---- > [68 72 60 66 68 73 64  1 77 64 62 84 62]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(68, shape=(), dtype=int32) :  i\n",
      "tf.Tensor(72, shape=(), dtype=int32) :  m\n",
      "tf.Tensor(60, shape=(), dtype=int32) :  a\n",
      "tf.Tensor(66, shape=(), dtype=int32) :  g\n",
      "tf.Tensor(68, shape=(), dtype=int32) :  i\n"
     ]
    }
   ],
   "source": [
    "#Length of a single input\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)\n",
    "\n",
    "#convert to tensor\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(i, \": \", idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'imagine recycling old game mechanics and calling the last of us 2 an innovative game\\nimagine making e'\n",
      "'llie sing a full acoustic cover of take on me and expecting the last of us 2 to be a game of the year'\n",
      "' contender\\nimagine a studio expecting their game to be a masterpiece after overworking its devs so mu'\n",
      "'ch that one of them threatened to leak the game just to get paid\\nOur love for anime girls actually st'\n",
      "'ems from the greeks who made an entire religion out of a 2D right triangle\\ni find it hard to believe '\n"
     ]
    }
   ],
   "source": [
    "#Make batches of seq_length\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate and shift (make train and target)\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'imagine recycling old game mechanics and calling the last of us 2 an innovative game\\nimagine making '\n",
      "'magine recycling old game mechanics and calling the last of us 2 an innovative game\\nimagine making e' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Given [0:99], predict [1:100] \n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(repr(''.join(idx2char[input_example])))\n",
    "    print(repr(''.join(idx2char[target_example])), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 68 ('i')\n",
      "  expected output: 72 ('m')\n",
      "Step    1\n",
      "  input: 72 ('m')\n",
      "  expected output: 60 ('a')\n",
      "Step    2\n",
      "  input: 60 ('a')\n",
      "  expected output: 66 ('g')\n",
      "Step    3\n",
      "  input: 66 ('g')\n",
      "  expected output: 68 ('i')\n",
      "Step    4\n",
      "  input: 68 ('i')\n",
      "  expected output: 73 ('n')\n"
     ]
    }
   ],
   "source": [
    "#visualization of training task for each rnn unit\n",
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000 #buffer size is for memory i think\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#64 training examples of seq length 100\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the thing (Personal task: change to LSTM to learn how to build ur own )\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        \n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.Dense(vocab_size) \n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 86)\n"
     ]
    }
   ],
   "source": [
    "# 64 batch size, 100 seq length per batch, 86 vocab size (unique characters/tokens)\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           22016     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 86)            88150     \n",
      "=================================================================\n",
      "Total params: 4,048,470\n",
      "Trainable params: 4,048,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "With the setup of RNN, text generation will be treated like a basic supervised classification problem (given char x, predict char y), meaning we can use standard backprop rules and loss functions (cross entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 86)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.453286\n"
     ]
    }
   ],
   "source": [
    "#mean loss for the batch of 64 is 4.45\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
